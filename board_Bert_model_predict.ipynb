{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "board_Bert_model_predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN9-KrqRxRuZ"
      },
      "source": [
        "!pip install flask\n",
        "!pip install flask_ngrok\n",
        "!pip install wtforms\n",
        "!pip install sqlalchemy\n",
        "!pip install mysql-connector-python\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/ML/HanBert-54kN/')\n",
        "\n",
        "import tokenization\n",
        "from keras.models import load_model\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "from transformers import *\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(\"/content/gdrive/My Drive/ML/HanBert-54kN/vocab_54k.txt\", use_moran=True)\n",
        "\n",
        "cls_token_id = 3\n",
        "sep_token_id = 4\n",
        "MAX_SEQUENCE_LENGTH = 140\n",
        "\n",
        "def convert_to_inputs(text, tokenizer,max_seq_len):\n",
        "    def return_id(str1,length):\n",
        "        token = tokenizer.tokenize(text)\n",
        "        if len(token) > max_seq_len-2:\n",
        "            token = token[:max_seq_len-2]\n",
        "\n",
        "        inputs_ids = tokenizer.convert_tokens_to_ids(token)    \n",
        "        inputs_ids = [cls_token_id] + inputs_ids + [sep_token_id]\n",
        "        input_mask = [1] * len(inputs_ids) #attention_mask\n",
        "\n",
        "        padding_length = length - len(inputs_ids)\n",
        "        inputs_ids = inputs_ids + ([0] * padding_length)\n",
        "        input_mask = input_mask + ([0] * padding_length)\n",
        "        segment_ids = [0] * len(inputs_ids) #token_type_ids\n",
        "        return [inputs_ids, input_mask, segment_ids]\n",
        "\n",
        "    input_ids, input_masks, input_segments = return_id(text, max_seq_len)\n",
        "\n",
        "    return [input_ids, input_masks, input_segments]\n",
        "\n",
        "def compute_outputs(df):\n",
        "    return np.asarray(df['label'])\n",
        "    \n",
        "def compute_inputs(df, tokenizer, max_sequence_length):\n",
        "    input_ids, segment_ids, input_mask = [], [], []\n",
        "    for document in df['document']:\n",
        "        inp_ids, inp_mask, seg_ids = convert_to_inputs(document, tokenizer, max_sequence_length)\n",
        "\n",
        "        input_ids.append(inp_ids)\n",
        "        segment_ids.append(seg_ids)\n",
        "        input_mask.append(inp_mask)\n",
        "    return [np.asarray(input_ids, dtype=np.int32),\n",
        "            np.asarray(input_mask, dtype=np.int32), \n",
        "            np.asarray(segment_ids, dtype=np.int32)]\n",
        "\n",
        "def create_model():\n",
        "    ids = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    seg = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    \n",
        "    \n",
        "    config = BertConfig.from_json_file('/content/gdrive/My Drive/ML/HanBert-54kN/bert_config.json')\n",
        "    config.output_hidden_states = False\n",
        "    bert_model = TFBertModel.from_pretrained('/content/gdrive/My Drive/HanBert-54kN-torch.tar/HanBert-54kN-torch', config=config, from_pt=True)\n",
        "\n",
        "    x = bert_model([ids, mask, seg])[0]\n",
        "\n",
        "    \n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, mask, seg,], outputs=x)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def customLoadModel(model):\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "    model.load_weights('/content/gdrive/My Drive/ML/HanBert-54kN/bert_model_nsmc_011.h5')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bx0eJz4qigl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86d2fdb-430c-46c8-c7ed-d8aca091fc4c"
      },
      "source": [
        "import flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "from sklearn.externals import joblib\n",
        "import numpy as np\n",
        "from wtforms import Form, TextAreaField, validators\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "\n",
        "@app.route(\"/predict\", methods=['POST'])\n",
        "def check():\n",
        "    if request.method == 'POST':\n",
        "        comment = request.json.get('comment')\n",
        "        test = pd.DataFrame({ 'document' : [comment]})\n",
        "        test_inputs = compute_inputs(test, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "        # 입력데이터 예측\n",
        "        prediction = loaded_model.predict(test_inputs)\n",
        "        prob = (prediction * 100) if prediction >= 0.5 else ((1 - prediction) * 100)\n",
        "\n",
        "        # 예측 값을 1차원 배열로부터 확인 가능한 문자열로 변환\n",
        "        label = 'positive' if prediction >= 0.5 else 'negative'\n",
        "    return jsonify({'result': label})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 모델 로드\n",
        "    loaded_model = customLoadModel(model)\n",
        "    # Flask 서비스 스타트\n",
        "    app.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://51970cb53f3e.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [08/Apr/2021 13:26:56] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [08/Apr/2021 13:27:32] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [08/Apr/2021 13:28:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [08/Apr/2021 13:28:14] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}